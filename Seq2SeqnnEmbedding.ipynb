{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import json\n",
    "import pickle\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge import Rouge\n",
    "from nltk import sent_tokenize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Pytorch library for training\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.96 s, sys: 785 ms, total: 9.74 s\n",
      "Wall time: 9.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv('wikihowSep.csv')\n",
    "data = data[:100000]\n",
    "data = data.astype(str)\n",
    "rows, columns = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_map={\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd've\": \"how did have\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"might have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"shall'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"will't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"would't\": \"would not\",\n",
    "    \"would't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you have all\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "}\n",
    "\n",
    "def expand_contractions(sent, mapping):\n",
    "    #pattern for matching contraction with their expansions\n",
    "    pattern = re.compile('({})'.format('|'.join(mapping.keys())), flags=re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    def expand_map(contraction):\n",
    "        #using group method to access subgroups of the match\n",
    "        match = contraction.group(0)\n",
    "        #to retain correct case of the word\n",
    "        first_char = match[0]\n",
    "        #find out the expansion\n",
    "        expansion = mapping.get(match) if mapping.get(match) else mapping.get(match.lower())\n",
    "        expansion = first_char + expansion[1:]\n",
    "        return expansion\n",
    "    #using sub method to replace all contractions with their expansions for a sentence\n",
    "    #function expand_map will be called for every non overlapping occurence of the pattern\n",
    "    expand_sent = pattern.sub(expand_map, sent)\n",
    "    return expand_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_word'] = data['text'].apply(lambda x: len(str(x).split()))\n",
    "num_word = np.sort(data['num_word'].values)\n",
    "\n",
    "data['num_word_hl'] = data['headline'].apply(lambda x: len(str(x).split()))\n",
    "num_word_hl = np.sort(data['num_word_hl'].values)\n",
    "\n",
    "min_text_len = num_word[int(len(num_word)*0.1)]\n",
    "max_text_len = num_word[int(len(num_word)*0.95)]\n",
    "\n",
    "min_hl_len = num_word_hl[int(len(num_word_hl)*0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_ratio_threshold = 0.75\n",
    "\n",
    "del_idx = []\n",
    "for i in range(rows):\n",
    "#     if data['num_word'][i] < max_text_len and data['num_word'][i] > min_text_len:\n",
    "    if data['num_word'][i] < min_text_len:\n",
    "        del_idx.append(i)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if max_text_len < data['num_word'][i]:\n",
    "        del_idx.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if data['num_word_hl'][i] > headline_ratio_threshold*data['num_word'][i]:\n",
    "        del_idx.append(i)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if data['num_word_hl'][i] < min_hl_len:\n",
    "        del_idx.append(i)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.drop(del_idx)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77774, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(dataframe, target_col): \n",
    "    # Extraction from dataframe into a list\n",
    "    text = [article for article in getattr(dataframe, target_col)]\n",
    "    \n",
    "    # Removing accented characters\n",
    "    text = [unicodedata.normalize('NFKD', sentence).encode('ascii', 'ignore').decode('utf-8', 'ignore') for sentence in text]\n",
    "    \n",
    "    # Expanding contractions\n",
    "    text = [expand_contractions(sentence, contraction_map) for sentence in text]\n",
    "\n",
    "    # Removing special characters\n",
    "    pat1 = r'[^a-zA-z0-9.,!?\\s]' \n",
    "    # pat1 = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    text = [re.sub(pat1, '', sentence) for sentence in text]\n",
    "    \n",
    "    # Removing extra commas\n",
    "    pat2 = r'[.]+[\\n]+[,]'\n",
    "    text = [re.sub(pat2,\".\\n\", sentence) for sentence in text]\n",
    "    \n",
    "    # Removing extra whitespaces and tabs\n",
    "    # pat3 = r'^\\s*|\\s\\s*'\n",
    "    pat3 = r'^\\s+$|\\s+$'\n",
    "    text = [re.sub(pat3, '', sentence).strip() for sentence in text]\n",
    "    \n",
    "    # Add space before '.'\n",
    "    pat4 = r'\\.|\\?|\\ï¼|\\,'\n",
    "    text = [re.sub(pat4, ' ', sentence) for sentence in text]\n",
    "    \n",
    "    # Lowercase\n",
    "    text = [sentence.lower() for sentence in text]\n",
    "    \n",
    "    # Tokenize\n",
    "    text = [('sos ' + sentence + ' eos').split() for sentence in text]\n",
    "    \n",
    "    return np.array(text, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.4 s, sys: 343 ms, total: 50.7 s\n",
      "Wall time: 51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_data = data_loader(data_new, 'text')\n",
    "headline_data = data_loader(data_new, 'headline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77774,), (77774,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.shape, headline_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, headline_train, headline_test = train_test_split(text_data, headline_data, test_size=0.1, random_state=1)\n",
    "text_train, text_dev, headline_train, headline_dev = train_test_split(text_train, headline_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "del text_data, headline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62996,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sorter(text, headline): \n",
    "    headline = [y for x,y in sorted(zip(text, headline), key = lambda pair: len(pair[0]), reverse = True)]\n",
    "    text = list(text)\n",
    "    text.sort(key = lambda x: len(x), reverse = True)\n",
    "\n",
    "    return np.array(text), np.array(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, headline_train = data_sorter(text_train, headline_train)\n",
    "text_test,  headline_test  = data_sorter(text_test, headline_test)\n",
    "text_dev,   headline_dev   = data_sorter(text_dev, headline_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    PAD_token = 0   # Used for padding short sentences\n",
    "    SOS_token = 1   # Start-of-sentence token\n",
    "    EOS_token = 2   # End-of-sentence token\n",
    "    UNK_token = 3   # Out-of-vocabulary token\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"pad\":0, \"sos\":1, \"eos\":2, \"unk\":3}\n",
    "        self.word2count = {\"pad\":0, \"sos\":0, \"eos\":0, \"unk\":0}              \n",
    "        self.index2word = {0: \"pad\", 1: \"sos\", 2: \"eos\", 3: \"unk\"}\n",
    "        self.num_words = 4\n",
    "        self.num_sentences = 0\n",
    "        self.longest_sentence = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def add_sentence(self, sentence):\n",
    "        sentence_len = 0\n",
    "        for word in sentence:           \n",
    "            sentence_len += 1\n",
    "            self.add_word(word)\n",
    "        if sentence_len > self.longest_sentence:\n",
    "            self.longest_sentence = sentence_len\n",
    "        self.num_sentences += 1\n",
    "\n",
    "    def to_word(self, index):\n",
    "        return self.index2word[index]\n",
    "\n",
    "    def to_index(self, word):\n",
    "        return self.word2index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocabulary = Vocabulary('text')\n",
    "headline_vocabulary = Vocabulary('headline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text\n",
    "for i in range(len(text_train)):\n",
    "    text_vocabulary.add_sentence(text_train[i])\n",
    "    for word in text_train[i]:\n",
    "        text_vocabulary.add_word(word)\n",
    "for i in range(len(text_dev)):\n",
    "    text_vocabulary.add_sentence(text_dev[i])\n",
    "    for word in text_dev[i]:\n",
    "        text_vocabulary.add_word(word)\n",
    "#headline\n",
    "for i in range(len(headline_train)):\n",
    "    headline_vocabulary.add_sentence(headline_train[i])\n",
    "    for word in headline_train[i]:\n",
    "        headline_vocabulary.add_word(word)\n",
    "for i in range(len(headline_dev)):\n",
    "    headline_vocabulary.add_sentence(headline_dev[i])\n",
    "    for word in headline_dev[i]:\n",
    "        headline_vocabulary.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57237\n",
      "18431\n"
     ]
    }
   ],
   "source": [
    "print(len(text_vocabulary.word2index.keys()))\n",
    "print(len(headline_vocabulary.word2index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2in(data,vocabulary):\n",
    "    data_idx = []\n",
    "    lengths = []\n",
    "    for i in range(len(data)):\n",
    "        idx = []\n",
    "        lengths.append(len(data[i]))\n",
    "        for word in data[i]:\n",
    "            try:\n",
    "                word2index = vocabulary.to_index(word)\n",
    "            except:\n",
    "                word2index = vocabulary.to_index('unk')\n",
    "            idx.append(word2index)\n",
    "        data_idx.append(torch.tensor(idx))\n",
    "    lengths = torch.tensor(lengths)\n",
    "    data_pad = torch.nn.utils.rnn.pad_sequence(data_idx, batch_first=True, padding_value=0.0)\n",
    "    return data_idx, data_pad, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_idx, text_train_pad, text_train_lengths = w2in(text_train,text_vocabulary)\n",
    "headline_train_idx, headline_train_pad, headline_train_lengths = w2in(headline_train,headline_vocabulary)\n",
    "\n",
    "text_dev_idx, text_dev_pad, text_dev_lengths = w2in(text_dev,text_vocabulary)\n",
    "headline_dev_idx, headline_dev_pad, headline_dev_lengths = w2in(headline_dev, headline_vocabulary)\n",
    "\n",
    "text_test_idx, text_test_pad, text_test_lengths = w2in(text_test,text_vocabulary)\n",
    "headline_test_idx, headline_test_pad, headline_test_lengths = w2in(headline_test, headline_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([62996, 202])\n",
      "torch.Size([62996, 76])\n",
      "torch.Size([62996])\n",
      "57237\n"
     ]
    }
   ],
   "source": [
    "print(text_train_pad.shape)\n",
    "print(headline_train_pad.shape)\n",
    "print(text_train_lengths.shape)\n",
    "print(len(text_vocabulary.word2index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zip text and headline together for dataloader\n",
    "traindata = torch.utils.data.TensorDataset(text_train_pad, headline_train_pad, text_train_lengths, headline_train_lengths)\n",
    "#trainlength = torch.utils.data.TensorDataset(text_train_lengths, headline_train_lengths)\n",
    "\n",
    "devdata = torch.utils.data.TensorDataset(text_dev_pad, headline_dev_pad, text_dev_lengths, headline_dev_lengths)\n",
    "#devlength = torch.utils.data.TensorDataset(text_dev_lengths, headline_dev_lengths)\n",
    "\n",
    "testdata = torch.utils.data.TensorDataset(text_test_pad, headline_test_pad, text_test_lengths, headline_test_lengths)\n",
    "#testlength = torch.utils.data.TensorDataset(text_test_lengths, headline_test_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set batch size and split data after padding to batches\n",
    "def batch_dataloader(data, Batch_size):\n",
    "    data_dataloader = torch.utils.data.DataLoader(data, batch_size=Batch_size, shuffle=False, num_workers=0)\n",
    "#     for i in data_dataloader:\n",
    "#         i = torch.transpose(i, 0 ,1)\n",
    "#         print(data_dataloader)\n",
    "    \n",
    "    return data_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training data batching\n",
    "trainloader = batch_dataloader(traindata, 50)\n",
    "#trainlen = batch_dataloader(trainlength, 15)\n",
    "\n",
    "devloader = batch_dataloader(devdata, 30)\n",
    "#devlen = batch_dataloader(devlength, 2)\n",
    "\n",
    "testloader = batch_dataloader(testdata, 30)\n",
    "#testlen = batch_dataloader(testlength, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transpose dataset for training\n",
    "text_testrun, hl_testrun, text_len, hl_len = next(iter(trainloader))\n",
    "#text_len, hl_len = next(iter(trainlen))\n",
    "\n",
    "text_testrun = torch.transpose(text_testrun, 0 ,1)\n",
    "hl_testrun = torch.transpose(hl_testrun, 0 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([202, 50]), torch.Size([76, 50]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_testrun.shape, hl_testrun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18431"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headline_vocabulary.index2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set parameters\n",
    "input_size = int(len(text_vocabulary.index2word.keys()))\n",
    "output_size = int(len(headline_vocabulary.index2word.keys()))\n",
    "\n",
    "enc_emb_size = 200\n",
    "dec_emb_size = 200\n",
    "hid_size = 128\n",
    "\n",
    "n_layers = 2\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hid_size, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hid_size = hid_size\n",
    "        self.input_size = input_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hid_size, n_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear\n",
    "        \n",
    "#         self.lstm = nn.LSTM(emb_size, hid_size, n_layers, dropout=dropout, bidirectional = True)\n",
    "        \n",
    "\n",
    "    def forward(self, x, x_length):\n",
    "        embedded = self.embedding(x) \n",
    "        embedded = nn.utils.rnn.pack_padded_sequence(embedded, x_length.numpy(),batch_first=False)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 50, 128]), torch.Size([2, 50, 128]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(input_size, enc_emb_size, hid_size, n_layers, enc_dropout).to(device)\n",
    "\n",
    "hidden, cell = encoder(text_testrun, text_len)\n",
    "hidden.shape, cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, emb_size, hid_size, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hid_size = hid_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hid_size, n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hid_size, output_size, bias = True)\n",
    "\n",
    "    def forward(self, output, hidden, cell):\n",
    "        embedded = self.embedding(output.unsqueeze(0))\n",
    "\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        \n",
    "        prediction = self.out(outputs.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 18431]), torch.Size([2, 50, 128]), torch.Size([2, 50, 128]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(output_size, dec_emb_size, hid_size, n_layers, dec_dropout)\n",
    "\n",
    "prediction, hidden, cell = decoder(hl_testrun[0], hidden, cell)\n",
    "prediction.shape, hidden.shape, cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder: Encoder1, decoder: Decoder, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, text_batch, text_batch_len, headline_batch, teacher_forcing_ratio: float=0.5):\n",
    "        max_len, batch_size = headline_batch.shape\n",
    "        headline_vocab_size = self.decoder.output_size\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, headline_vocab_size).to(self.device)\n",
    "\n",
    "        # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "        hidden, cell = self.encoder(text_batch, text_batch_len)\n",
    "        \n",
    "        hl_batch_i = headline_batch[0]\n",
    "        \n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden, cell = self.decoder(hl_batch_i, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                hl_batch_i = headline_batch[i]\n",
    "            else:\n",
    "                hl_batch_i = prediction.argmax(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder1(\n",
       "    (embedding): Embedding(57237, 200)\n",
       "    (lstm): LSTM(200, 128, num_layers=2, dropout=0.1)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(57237, 200)\n",
       "    (lstm): LSTM(200, 128, num_layers=2, dropout=0.1)\n",
       "    (out): Linear(in_features=128, out_features=18431, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(input_size, enc_emb_size, hid_size, n_layers, enc_dropout)\n",
    "decoder = Decoder(output_size, dec_emb_size, hid_size, n_layers, dec_dropout)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device)\n",
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(seq2seq, trainloader, optimizer, criterion):\n",
    "    seq2seq.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for text_batch, hl_batch, text_len, hl_len in trainloader:\n",
    "        text_batch = torch.transpose(text_batch, 0, 1)\n",
    "        hl_batch = torch.transpose(hl_batch, 0, 1)\n",
    "        \n",
    "        ## send to cuda\n",
    "        #text_batch = text_batch.to(device)\n",
    "        #hl_batch = hl_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text_batch = text_batch[:text_len.max()].to(device)\n",
    "        hl_batch = hl_batch[:hl_len.max()].to(device)\n",
    "                                 \n",
    "        outputs = seq2seq(text_batch, text_len, hl_batch)\n",
    "        outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "        \n",
    "        hl_flatten = hl_batch[1:].reshape(-1)\n",
    "        loss = criterion(outputs_flatten, hl_flatten)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(seq2seq, trainloader, criterion):\n",
    "    seq2seq.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, hl_batch, text_len, hl_len in trainloader:\n",
    "            text_batch = torch.transpose(text_batch, 0, 1)\n",
    "            hl_batch = torch.transpose(hl_batch, 0, 1)\n",
    "\n",
    "            ## send to cuda\n",
    "            #text_batch = text_batch.to(device)\n",
    "            #hl_batch = hl_batch.to(device)\n",
    "            \n",
    "            text_batch = text_batch[:text_len.max()].to(device)\n",
    "            hl_batch = hl_batch[:hl_len.max()].to(device)\n",
    "            # teacher forcing not used\n",
    "            outputs = seq2seq(text_batch, text_len, hl_batch, teacher_forcing_ratio=0) \n",
    "            outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "            \n",
    "            hl_flatten = hl_batch[1:].reshape(-1)\n",
    "            loss = criterion(outputs_flatten, hl_flatten)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 63m 45s\n",
      "\tTrain Loss: 6.104 | Train PPL: 447.779\n",
      "\t Val. Loss: 6.088 |  Val. PPL: 440.672\n",
      "Epoch: 02 | Time: 64m 1s\n",
      "\tTrain Loss: 5.713 | Train PPL: 302.898\n",
      "\t Val. Loss: 6.075 |  Val. PPL: 434.874\n",
      "Epoch: 03 | Time: 64m 35s\n",
      "\tTrain Loss: 5.511 | Train PPL: 247.341\n",
      "\t Val. Loss: 5.960 |  Val. PPL: 387.725\n",
      "Epoch: 04 | Time: 70m 0s\n",
      "\tTrain Loss: 5.273 | Train PPL: 194.937\n",
      "\t Val. Loss: 5.860 |  Val. PPL: 350.792\n",
      "Epoch: 05 | Time: 71m 26s\n",
      "\tTrain Loss: 5.072 | Train PPL: 159.569\n",
      "\t Val. Loss: 5.829 |  Val. PPL: 339.952\n",
      "Epoch: 06 | Time: 70m 18s\n",
      "\tTrain Loss: 4.920 | Train PPL: 137.039\n",
      "\t Val. Loss: 5.839 |  Val. PPL: 343.527\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-317d70cc9bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0me1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-0ade89bc4390>\u001b[0m in \u001b[0;36mtrain1\u001b[0;34m(seq2seq, trainloader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_flatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl_flatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "best_valid_loss = float('inf')\n",
    "e1 = []\n",
    "e2 = []\n",
    "\n",
    "for epoch in range(num_epoch):    \n",
    "    start_time = time.time()\n",
    "    train_loss = train1(seq2seq, trainloader, optimizer, criterion)\n",
    "    e1.append(train_loss)\n",
    "    valid_loss = evaluate1(seq2seq, devloader, criterion)\n",
    "    e2.append(valid_loss)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss + 0.01\n",
    "        torch.save(seq2seq.state_dict(), 'tut1-model1.pt')\n",
    "\n",
    "    # it's easier to see a change in perplexity between epoch as it's an exponential\n",
    "    # of the loss, hence the scale of the measure is much bigger\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorry this is not a warning but cutten by myself by mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 71m 24s\n",
      "\tTrain Loss: 4.741 | Train PPL: 114.565\n",
      "\t Val. Loss: 5.827 |  Val. PPL: 339.325\n",
      "Epoch: 08 | Time: 81m 47s\n",
      "\tTrain Loss: 4.649 | Train PPL: 104.468\n",
      "\t Val. Loss: 5.803 |  Val. PPL: 331.158\n",
      "Epoch: 09 | Time: 70m 16s\n",
      "\tTrain Loss: 4.533 | Train PPL:  93.017\n",
      "\t Val. Loss: 5.834 |  Val. PPL: 341.719\n",
      "Epoch: 10 | Time: 67m 29s\n",
      "\tTrain Loss: 4.443 | Train PPL:  85.057\n",
      "\t Val. Loss: 5.856 |  Val. PPL: 349.191\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(6,10):    \n",
    "    start_time = time.time()\n",
    "    train_loss = train1(seq2seq, trainloader, optimizer, criterion)\n",
    "    e1.append(train_loss)\n",
    "    valid_loss = evaluate1(seq2seq, devloader, criterion)\n",
    "    e2.append(valid_loss)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss + 0.01\n",
    "        torch.save(seq2seq.state_dict(), 'tut1-model1.pt')\n",
    "\n",
    "    # it's easier to see a change in perplexity between epoch as it's an exponential\n",
    "    # of the loss, hence the scale of the measure is much bigger\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load('tut1-model1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = range(1,11)\n",
    "plt.plot(n,e1)\n",
    "plt.plot(n,e2)\n",
    "plt.legend(['train loss','validation loss'])\n",
    "plt.savefig('Seq-to-Seqnn.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "target = []\n",
    "for text_batch, hl_batch, text_len, headline_len in testloader:\n",
    "    text_batch = torch.transpose(text_batch, 0, 1) \n",
    "    hl_batch = torch.transpose(hl_batch, 0, 1)\n",
    "    text_batch = text_batch[:text_len.max()]\n",
    "    hl_batch = hl_batch[:headline_len.max()]\n",
    "    with torch.no_grad():\n",
    "        a = seq2seq(text_batch, text_len, hl_batch, teacher_forcing_ratio=0)\n",
    "        a = a.argmax(2)\n",
    "    for i in range(a.shape[1]):\n",
    "        outputs.append(' '.join([headline_vocabulary.index2word[j] for j in a[:,i].numpy() if (j != 0) & (j != 1) & (j != 2)]))\n",
    "        target.append(' '.join([headline_vocabulary.index2word[j] for j in hl_batch[:,i].numpy() if (j != 0) & (j != 1) & (j != 2)])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "r1 = [rouge.get_scores(o, t)[0][\"rouge-1\"]['r'] for o, t in zip(outputs, target)]\n",
    "r2 = [rouge.get_scores(o, t)[0][\"rouge-2\"]['r'] for o, t in zip(outputs, target)]\n",
    "rl = [rouge.get_scores(o, t)[0][\"rouge-l\"]['r'] for o, t in zip(outputs, target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge1 = np.array(r1).mean()\n",
    "rouge2 = np.array(r2).mean()\n",
    "rougel = np.array(rl).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11359736961329989, 0.022366101976527317, 0.11084906067284304)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge1,rouge2,rougel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'create a weekly routine alternating cardio and strength training'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = open('S2Snn.txt', 'w')  \n",
    "for value in outputs:  \n",
    "     filename.write(value+'\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = np.array(e1)\n",
    "np.save('train loss nn 128.npy', e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 = np.array(e2)\n",
    "np.save('val loss nn 128.npy', e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

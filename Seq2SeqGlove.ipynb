{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eyaX6ahtGqTo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import json\n",
    "import pickle\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from nltk import sent_tokenize\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from rouge import Rouge\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Pytorch library for training\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjSi17gGG4CT",
    "outputId": "a6ac608c-40a4-4b1c-dbf9-554468bd4e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcLSv82kG_0b"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"drive/MyDrive\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "009KllpcDsXh"
   },
   "source": [
    "###Import GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pL-2jtdHByn",
    "outputId": "7f412ad9-6034-4f8a-b2a1-06b8653ed2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-27 21:36:05--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-05-27 21:36:05--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-05-27 21:36:05--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip          3%[                    ]  28.71M  23.5MB/s               ^C\n",
      "Archive:  glove.6B.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of glove.6B.zip or\n",
      "        glove.6B.zip.zip, and cannot find glove.6B.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "# Set desired dimension of embeddings from [50, 100, 200, 300]\n",
    "embed_dim = 200\n",
    "\n",
    "# Download and unzip GloVe embedding\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dgwa6MADJyp2",
    "outputId": "5d71f357-6a4a-4707-8ef8-e8470c6732ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input your pre-train txt path and parse the data\n",
    "embed_dim = 200\n",
    "path = 'glove.6B.200d.txt'\n",
    "\n",
    "embed_dict = {}\n",
    "with open(path,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        w = l.split()[0]\n",
    "        v = np.array(l.split()[1:]).astype('float')\n",
    "        embed_dict[w] = v\n",
    "\n",
    "embed_dict['@@_unknown_@@'] = np.random.random(embed_dim)\n",
    "\n",
    "# remove all the unnecesary files\n",
    "!rm -rf glove.6B.zip\n",
    "!rm -rf glove.6B.50d.txt\n",
    "!rm -rf glove.6B.100d.txt\n",
    "!rm -rf glove.6B.300d.txt\n",
    "\n",
    "# check the length of the dictionary\n",
    "len(embed_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEuVkCWND2m3"
   },
   "source": [
    "###Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHmEgmJoLJ4g",
    "outputId": "b623990e-9b95-4004-e6da-a02d0857c3a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.25 s, sys: 800 ms, total: 9.05 s\n",
      "Wall time: 9.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv('wikihowSep.csv')\n",
    "data = data[:100000]\n",
    "data = data.astype(str)\n",
    "rows, columns = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fPvkXg5TLUtI"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlZf9QgiD7hG"
   },
   "source": [
    "###Removing sentence which are too long or too short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GyZbXN20MCaA"
   },
   "outputs": [],
   "source": [
    "contraction_map={\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd've\": \"how did have\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"might have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"shall'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"will't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"would't\": \"would not\",\n",
    "    \"would't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you have all\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "}\n",
    "\n",
    "def expand_contractions(sent, mapping):\n",
    "    #pattern for matching contraction with their expansions\n",
    "    pattern = re.compile('({})'.format('|'.join(mapping.keys())), flags=re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    def expand_map(contraction):\n",
    "        #using group method to access subgroups of the match\n",
    "        match = contraction.group(0)\n",
    "        #to retain correct case of the word\n",
    "        first_char = match[0]\n",
    "        #find out the expansion\n",
    "        expansion = mapping.get(match) if mapping.get(match) else mapping.get(match.lower())\n",
    "        expansion = first_char + expansion[1:]\n",
    "        return expansion\n",
    "    #using sub method to replace all contractions with their expansions for a sentence\n",
    "    #function expand_map will be called for every non overlapping occurence of the pattern\n",
    "    expand_sent = pattern.sub(expand_map, sent)\n",
    "    return expand_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "S6zvw4cRMKLf"
   },
   "outputs": [],
   "source": [
    "data['num_word'] = data['text'].apply(lambda x: len(str(x).split()))\n",
    "num_word = np.sort(data['num_word'].values)\n",
    "\n",
    "data['num_word_hl'] = data['headline'].apply(lambda x: len(str(x).split()))\n",
    "num_word_hl = np.sort(data['num_word_hl'].values)\n",
    "\n",
    "min_text_len = num_word[int(len(num_word)*0.1)]\n",
    "max_text_len = num_word[int(len(num_word)*0.95)]\n",
    "\n",
    "min_hl_len = num_word_hl[int(len(num_word_hl)*0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4L09KIjSM4Qd"
   },
   "outputs": [],
   "source": [
    "headline_ratio_threshold = 0.75\n",
    "\n",
    "del_idx = []\n",
    "for i in range(rows):\n",
    "#     if data['num_word'][i] < max_text_len and data['num_word'][i] > min_text_len:\n",
    "    if data['num_word'][i] < min_text_len:\n",
    "        del_idx.append(i)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if max_text_len < data['num_word'][i]:\n",
    "        del_idx.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if data['num_word_hl'][i] > headline_ratio_threshold*data['num_word'][i]:\n",
    "        del_idx.append(i)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if data['num_word_hl'][i] < min_hl_len:\n",
    "        del_idx.append(i)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Tv_beD0NM7ch"
   },
   "outputs": [],
   "source": [
    "data_new = data.drop(del_idx)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XneeLgucNAHH",
    "outputId": "3f8edd73-758f-4a26-a3ad-35783e3ad58b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77774, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94sxESVZEQrL"
   },
   "source": [
    "###Removing special characters and extra comma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z29-1okQNCXN"
   },
   "outputs": [],
   "source": [
    "def data_loader(dataframe, target_col): \n",
    "    # Extraction from dataframe into a list\n",
    "    text = [article for article in getattr(dataframe, target_col)]\n",
    "    \n",
    "    # Removing accented characters\n",
    "    text = [unicodedata.normalize('NFKD', sentence).encode('ascii', 'ignore').decode('utf-8', 'ignore') for sentence in text]\n",
    "    \n",
    "    # Expanding contractions\n",
    "    text = [expand_contractions(sentence, contraction_map) for sentence in text]\n",
    "\n",
    "    # Removing special characters\n",
    "    pat1 = r'[^a-zA-z0-9.,!?\\s]' \n",
    "    # pat1 = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    text = [re.sub(pat1, '', sentence) for sentence in text]\n",
    "    \n",
    "    # Removing extra commas\n",
    "    pat2 = r'[.]+[\\n]+[,]'\n",
    "    text = [re.sub(pat2,\".\\n\", sentence) for sentence in text]\n",
    "    \n",
    "    # Removing extra whitespaces and tabs\n",
    "    # pat3 = r'^\\s*|\\s\\s*'\n",
    "    pat3 = r'^\\s+$|\\s+$'\n",
    "    text = [re.sub(pat3, '', sentence).strip() for sentence in text]\n",
    "    \n",
    "    # Add space before '.'\n",
    "    pat4 = r'\\.|\\?|\\！|\\,'\n",
    "    text = [re.sub(pat4, ' ', sentence) for sentence in text]\n",
    "    \n",
    "    # Lowercase\n",
    "    text = [sentence.lower() for sentence in text]\n",
    "    \n",
    "    # Tokenize\n",
    "    text = [('sos ' + sentence + ' eos').split() for sentence in text]\n",
    "    \n",
    "    return np.array(text, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Oggcix3nNFmT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.7 s, sys: 329 ms, total: 51 s\n",
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_data = data_loader(data_new, 'text')\n",
    "headline_data = data_loader(data_new, 'headline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77774,), (77774,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.shape, headline_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ImuLBEn4NME-"
   },
   "outputs": [],
   "source": [
    "text_train, text_test, headline_train, headline_test = train_test_split(text_data, headline_data, test_size=0.1, random_state=1)\n",
    "text_train, text_dev, headline_train, headline_dev = train_test_split(text_train, headline_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xwgWcCh9NWNC"
   },
   "outputs": [],
   "source": [
    "del text_data, headline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzMIYaHcW7Ch",
    "outputId": "31b5a008-6e7b-4a7b-816c-18359821266a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62996,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oULmWvR6NcDf"
   },
   "outputs": [],
   "source": [
    "def data_sorter(text, headline): \n",
    "    headline = [y for x,y in sorted(zip(text, headline), key = lambda pair: len(pair[0]), reverse = True)]\n",
    "    text = list(text)\n",
    "    text.sort(key = lambda x: len(x), reverse = True)\n",
    "\n",
    "    return np.array(text), np.array(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "li3p-0HXNerH",
    "outputId": "17ed420f-4958-40c3-8875-060db630ef9f"
   },
   "outputs": [],
   "source": [
    "text_train, headline_train = data_sorter(text_train, headline_train)\n",
    "text_test,  headline_test  = data_sorter(text_test, headline_test)\n",
    "text_dev,   headline_dev   = data_sorter(text_dev, headline_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brmTE1zcEd5r"
   },
   "source": [
    "###Making vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NJQPn97oNoxN"
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    PAD_token = 0   # Used for padding short sentences\n",
    "    SOS_token = 1   # Start-of-sentence token\n",
    "    EOS_token = 2   # End-of-sentence token\n",
    "    UNK_token = 3   # Out-of-vocabulary token\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"pad\":0, \"sos\":1, \"eos\":2, \"unk\":3}\n",
    "        self.word2count = {\"pad\":0, \"sos\":0, \"eos\":0, \"unk\":0}              \n",
    "        self.index2word = {0: \"pad\", 1: \"sos\", 2: \"eos\", 3: \"unk\"}\n",
    "        self.num_words = 4\n",
    "        self.num_sentences = 0\n",
    "        self.longest_sentence = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def add_sentence(self, sentence):\n",
    "        sentence_len = 0\n",
    "        for word in sentence:           \n",
    "            sentence_len += 1\n",
    "            self.add_word(word)\n",
    "        if sentence_len > self.longest_sentence:\n",
    "            self.longest_sentence = sentence_len\n",
    "        self.num_sentences += 1\n",
    "\n",
    "    def to_word(self, index):\n",
    "        return self.index2word[index]\n",
    "\n",
    "    def to_index(self, word):\n",
    "        return self.word2index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CKB-nvTKNuB-"
   },
   "outputs": [],
   "source": [
    "text_vocabulary = Vocabulary('text')\n",
    "headline_vocabulary = Vocabulary('headline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "y98JSP8pN2lv"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text_train)):\n",
    "    text_vocabulary.add_sentence(text_train[i])\n",
    "    for word in text_train[i]:\n",
    "        text_vocabulary.add_word(word)\n",
    "for i in range(len(text_dev)):\n",
    "    text_vocabulary.add_sentence(text_dev[i])\n",
    "    for word in text_dev[i]:\n",
    "        text_vocabulary.add_word(word)\n",
    "for i in range(len(headline_train)):\n",
    "    headline_vocabulary.add_sentence(headline_train[i])\n",
    "    for word in headline_train[i]:\n",
    "        headline_vocabulary.add_word(word)\n",
    "for i in range(len(headline_dev)):\n",
    "    headline_vocabulary.add_sentence(headline_dev[i])\n",
    "    for word in headline_dev[i]:\n",
    "        headline_vocabulary.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qlnaRIfN9X_",
    "outputId": "51eeeb17-db99-4de6-853e-702b6c23c596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57237\n",
      "18431\n"
     ]
    }
   ],
   "source": [
    "print(len(text_vocabulary.word2index.keys()))\n",
    "print(len(headline_vocabulary.word2index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_dictionary\n",
    "with open('text.dictionary', 'wb') as text_dictionary_file:\n",
    "    pickle.dump(text_vocabulary, text_dictionary_file)\n",
    "\n",
    "# headline_dictionary\n",
    "with open('headline.dictionary', 'wb') as headline_dictionary_file:\n",
    "    pickle.dump(headline_vocabulary, headline_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PR6v_PcNEj4m"
   },
   "source": [
    "###Making embeddings corresponding to vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wACERHWdRJNs"
   },
   "outputs": [],
   "source": [
    "def extract_weight(text_dictionary):\n",
    "    pre_train_weight = []\n",
    "    for word_index in text_dictionary.index2word.keys():\n",
    "        if word_index != 0:\n",
    "            word = text_dictionary.index2word[word_index]\n",
    "            try:\n",
    "                word_vector = embed_dict[word].reshape(1,-1)\n",
    "            except:\n",
    "                word_vector = embed_dict['@@_unknown_@@'].reshape(1,-1) # handle unknown word\n",
    "            pre_train_weight = np.vstack([pre_train_weight,word_vector])\n",
    "    \n",
    "      # add for padding\n",
    "        elif word_index == 0:  \n",
    "            pre_train_weight = np.zeros((1, embed_dim))\n",
    "    return pre_train_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PImxjxvFOAP4",
    "outputId": "70db11dc-68eb-4c33-9547-0d427ec0f045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 38s, sys: 11min 6s, total: 22min 45s\n",
      "Wall time: 22min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pre_train_weight = extract_weight(text_vocabulary)\n",
    "pre_train_weight = np.array(pre_train_weight, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUTQ_HfJRK_U",
    "outputId": "ceb150c1-5f1b-4a47-9ba5-09521d6f261b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 1min, total: 2min 12s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pre_train_weight_head = extract_weight(headline_vocabulary)\n",
    "pre_train_weight_head = np.array(pre_train_weight_head, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57237, 200), (18431, 200))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_train_weight.shape, pre_train_weight_head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embedding.npy', pre_train_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embedding_headline.npy', pre_train_weight_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRZKwNKME56c"
   },
   "source": [
    "###Transform word into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CK9RL86xTiDw"
   },
   "outputs": [],
   "source": [
    "def w2in(data,vocabulary,embeddings):\n",
    "    data_idx = []\n",
    "    lengths = []\n",
    "    for i in range(len(data)):\n",
    "        idx = []\n",
    "        lengths.append(len(data[i]))\n",
    "        for word in data[i]:\n",
    "            try:\n",
    "                word2index = vocabulary.to_index(word)\n",
    "            except:\n",
    "                word2index = vocabulary.to_index('unk')\n",
    "            idx.append(word2index)\n",
    "        data_idx.append(torch.tensor(idx))\n",
    "    lengths = torch.tensor(lengths)\n",
    "    data_pad = torch.nn.utils.rnn.pad_sequence(data_idx, batch_first=True, padding_value=0.0)\n",
    "    return data_idx, data_pad, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eF3xJQ2cUR1F"
   },
   "outputs": [],
   "source": [
    "text_train_idx, text_train_pad, text_train_lengths = w2in(text_train,text_vocabulary, pre_train_weight)\n",
    "headline_train_idx, headline_train_pad, headline_train_lengths = w2in(headline_train,headline_vocabulary, pre_train_weight)\n",
    "\n",
    "text_dev_idx, text_dev_pad, text_dev_lengths = w2in(text_dev,text_vocabulary, pre_train_weight)\n",
    "headline_dev_idx, headline_dev_pad, headline_dev_lengths = w2in(headline_dev, headline_vocabulary, pre_train_weight)\n",
    "\n",
    "text_test_idx, text_test_pad, text_test_lengths = w2in(text_test,text_vocabulary, pre_train_weight)\n",
    "headline_test_idx, headline_test_pad, headline_test_lengths = w2in(headline_test, headline_vocabulary, pre_train_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TC7b5JoVUfhz",
    "outputId": "7d9596e5-4a4c-4c68-d411-c1f077116fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7778, 190])\n",
      "torch.Size([62996, 76])\n",
      "torch.Size([62996])\n",
      "57237\n"
     ]
    }
   ],
   "source": [
    "print(text_test_pad.shape)\n",
    "print(headline_train_pad.shape)\n",
    "print(text_train_lengths.shape)\n",
    "print(len(text_vocabulary.word2index.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ7Fj_pwFB_d"
   },
   "source": [
    "###Combine the data togther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "-BLopH3wYZTf"
   },
   "outputs": [],
   "source": [
    "## Zip text and headline together for dataloader\n",
    "traindata = torch.utils.data.TensorDataset(text_train_pad, headline_train_pad, text_train_lengths, headline_train_lengths)\n",
    "#trainlength = torch.utils.data.TensorDataset(text_train_lengths, headline_train_lengths)\n",
    "\n",
    "devdata = torch.utils.data.TensorDataset(text_dev_pad, headline_dev_pad, text_dev_lengths, headline_dev_lengths)\n",
    "#devlength = torch.utils.data.TensorDataset(text_dev_lengths, headline_dev_lengths)\n",
    "\n",
    "testdata = torch.utils.data.TensorDataset(text_test_pad, headline_test_pad, text_test_lengths, headline_test_lengths)\n",
    "#testlength = torch.utils.data.TensorDataset(text_test_lengths, headline_test_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('text_train_pad.npy', text_train_pad)\n",
    "np.save('text_train_lengths.npy', text_train_lengths)\n",
    "np.save('headline_train_pad.npy', headline_train_pad)\n",
    "np.save('headline_train_lengths.npy', headline_train_lengths)\n",
    "np.save('text_dev_pad.npy', text_dev_pad)\n",
    "np.save('text_dev_lengths.npy', text_dev_lengths)\n",
    "np.save('headline_dev_pad.npy', headline_dev_pad)\n",
    "np.save('headline_dev_lengths.npy', headline_dev_lengths)\n",
    "np.save('text_test_pad.npy', text_test_pad)\n",
    "np.save('text_test_lengths.npy', text_test_lengths)\n",
    "np.save('headline_test_pad.npy', headline_test_pad)\n",
    "np.save('headline_test_lengths.npy', headline_test_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "torch.save(testdata, 'testdata_zip.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CF_0h_NpYSbC"
   },
   "outputs": [],
   "source": [
    "## Set batch size and split data after padding to batches\n",
    "def batch_dataloader(data, Batch_size):\n",
    "    data_dataloader = torch.utils.data.DataLoader(data, batch_size=Batch_size, shuffle=False, num_workers=0)\n",
    "#     for i in data_dataloader:\n",
    "#         i = torch.transpose(i, 0 ,1)\n",
    "#         print(data_dataloader)\n",
    "    \n",
    "    return data_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcP8p82sFUMf"
   },
   "source": [
    "###Set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "3BPBXAnlYT6E"
   },
   "outputs": [],
   "source": [
    "## Training data batching\n",
    "trainloader = batch_dataloader(traindata, 100)\n",
    "#trainlen = batch_dataloader(trainlength, 15)\n",
    "\n",
    "devloader = batch_dataloader(devdata, 50)\n",
    "#devlen = batch_dataloader(devlength, 2)\n",
    "\n",
    "testloader = batch_dataloader(testdata, 50)\n",
    "#testlen = batch_dataloader(testlength, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-nSK4gY0VbIr"
   },
   "outputs": [],
   "source": [
    "## Transpose dataset for training\n",
    "text_testrun, hl_testrun, text_len, hl_len = next(iter(trainloader))\n",
    "#text_len, hl_len = next(iter(trainlen))\n",
    "\n",
    "text_testrun = torch.transpose(text_testrun, 0 ,1)\n",
    "hl_testrun = torch.transpose(hl_testrun, 0 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d5zEpcOefcx",
    "outputId": "1dd5d1d1-79cf-4286-f8ec-4ab329949686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([202, 100])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_testrun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_dictionary\n",
    "with open('Data/text.dictionary', 'rb') as text_dictionary_file: #for S2S and S2S+GAN\n",
    "    text_vocabulary = pickle.load(text_dictionary_file)\n",
    "# headline_dictionary\n",
    "with open('Data/headline.dictionary', 'rb') as headline_dictionary_file: #for S2S and S2S+GAN\n",
    "    headline_vocabulary = pickle.load(headline_dictionary_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0IFb6Q5FbVo"
   },
   "source": [
    "###Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "8bVjt8V2ilnz"
   },
   "outputs": [],
   "source": [
    "### Set parameters\n",
    "input_size = int(len(text_vocabulary.index2word.keys()))\n",
    "output_size = int(len(headline_vocabulary.index2word.keys()))\n",
    "\n",
    "enc_emb_size = 200\n",
    "dec_emb_size = 200\n",
    "hid_size = 256\n",
    "\n",
    "n_layers = 2\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4l3mgeLFjDL"
   },
   "source": [
    "###Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7eM5hKQlio96"
   },
   "outputs": [],
   "source": [
    "class Encoder1(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hid_size, n_layers, dropout, embeddings):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hid_size = hid_size\n",
    "        self.input_size = input_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = embeddings\n",
    "        self.lstm = nn.LSTM(emb_size, hid_size, n_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear\n",
    "        \n",
    "#         self.lstm = nn.LSTM(emb_size, hid_size, n_layers, dropout=dropout, bidirectional = True)\n",
    "        \n",
    "\n",
    "    def forward(self, x, x_length):\n",
    "        embedded = torch.tensor([[self.embedding[i] for i in x[:, seq]]for seq in range(x.shape[1])]).permute(1, 0, 2)\n",
    "        embedded = nn.utils.rnn.pack_padded_sequence(embedded, x_length.numpy(),batch_first=False)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "J_wnwE2OiyB-"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, emb_size, hid_size, n_layers, dropout, embeddings):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hid_size = hid_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = embeddings\n",
    "        self.lstm = nn.LSTM(emb_size, hid_size, n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hid_size, output_size, bias = True)\n",
    "\n",
    "    def forward(self, output, hidden, cell):\n",
    "        embedded = torch.tensor([self.embedding[x] for x in output]).float().unsqueeze(0)\n",
    "\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        \n",
    "        prediction = self.out(outputs.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxP3yaJkFr3N"
   },
   "source": [
    "###Sequence to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "sVkpA_owjS6I"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq1(nn.Module):\n",
    "    def __init__(self, encoder: Encoder1, decoder: Decoder, device: torch.device, embeddings):\n",
    "        super().__init__()\n",
    "        self.embedding = embeddings\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, text_batch, text_batch_len, headline_batch, teacher_forcing_ratio: float=0.5):\n",
    "        max_len, batch_size = headline_batch.shape\n",
    "        headline_vocab_size = self.decoder.output_size\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, headline_vocab_size).to(self.device)\n",
    "\n",
    "        # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "        hidden, cell = self.encoder(text_batch, text_batch_len)\n",
    "        \n",
    "        hl_batch_i = headline_batch[0]\n",
    "        \n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden, cell = self.decoder(hl_batch_i, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                hl_batch_i = headline_batch[i]\n",
    "            else:\n",
    "                hl_batch_i = prediction.argmax(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2y7gERAJEeL"
   },
   "source": [
    "###call for Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTI__k06jV-g",
    "outputId": "f3f92b9a-9dcb-4ace-d097-9752c9ad8363"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq1(\n",
       "  (encoder): Encoder1(\n",
       "    (lstm): LSTM(200, 256, num_layers=2, dropout=0.1)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm): LSTM(200, 256, num_layers=2, dropout=0.1)\n",
       "    (out): Linear(in_features=256, out_features=18431, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder1(input_size, enc_emb_size, hid_size, n_layers, enc_dropout, pre_train_weight)\n",
    "decoder = Decoder(output_size, dec_emb_size, hid_size, n_layers, dec_dropout, pre_train_weight_head)\n",
    "seq2seq = Seq2Seq1(encoder, decoder, device, pre_train_weight)\n",
    "seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvBiIQouFxID"
   },
   "source": [
    "###Training and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "m_k3ng0KjYDP"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ntNAxemHjapw"
   },
   "outputs": [],
   "source": [
    "def train1(seq2seq, trainloader, optimizer, criterion):\n",
    "    seq2seq.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for text_batch, hl_batch, text_len, hl_len in trainloader:\n",
    "        text_batch = torch.transpose(text_batch, 0, 1)\n",
    "        hl_batch = torch.transpose(hl_batch, 0, 1)\n",
    "        \n",
    "        ## send to cuda\n",
    "        #text_batch = text_batch.to(device)\n",
    "        #hl_batch = hl_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text_batch = text_batch[:text_len.max()].to(device)\n",
    "        hl_batch = hl_batch[:hl_len.max()].to(device)\n",
    "                                 \n",
    "        outputs = seq2seq(text_batch, text_len, hl_batch)\n",
    "        outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "        \n",
    "        hl_flatten = hl_batch[1:].reshape(-1)\n",
    "        loss = criterion(outputs_flatten, hl_flatten)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "DV0XTP9EjdSJ"
   },
   "outputs": [],
   "source": [
    "def evaluate1(seq2seq, trainloader, criterion):\n",
    "    seq2seq.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, hl_batch, text_len, hl_len in trainloader:\n",
    "            text_batch = torch.transpose(text_batch, 0, 1)\n",
    "            hl_batch = torch.transpose(hl_batch, 0, 1)\n",
    "\n",
    "            ## send to cuda\n",
    "            #text_batch = text_batch.to(device)\n",
    "            #hl_batch = hl_batch.to(device)\n",
    "            \n",
    "            text_batch = text_batch[:text_len.max()].to(device)\n",
    "            hl_batch = hl_batch[:hl_len.max()].to(device)\n",
    "            # teacher forcing not used\n",
    "            outputs = seq2seq(text_batch, text_len, hl_batch, teacher_forcing_ratio=0) \n",
    "            outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "            \n",
    "            hl_flatten = hl_batch[1:].reshape(-1)\n",
    "            loss = criterion(outputs_flatten, hl_flatten)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "LWNyivfZjgDk"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ticNGkSjjiQC",
    "outputId": "2e60f60a-914d-4de1-a099-3767a12eca81",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 86m 42s\n",
      "\tTrain Loss: 6.180 | Train PPL: 483.218\n",
      "\t Val. Loss: 6.107 |  Val. PPL: 449.108\n",
      "Epoch: 02 | Time: 80m 31s\n",
      "\tTrain Loss: 5.810 | Train PPL: 333.469\n",
      "\t Val. Loss: 6.053 |  Val. PPL: 425.283\n",
      "Epoch: 03 | Time: 77m 41s\n",
      "\tTrain Loss: 5.604 | Train PPL: 271.536\n",
      "\t Val. Loss: 5.954 |  Val. PPL: 385.260\n",
      "Epoch: 04 | Time: 76m 43s\n",
      "\tTrain Loss: 5.348 | Train PPL: 210.181\n",
      "\t Val. Loss: 5.797 |  Val. PPL: 329.258\n",
      "Epoch: 05 | Time: 74m 23s\n",
      "\tTrain Loss: 5.156 | Train PPL: 173.405\n",
      "\t Val. Loss: 5.740 |  Val. PPL: 311.046\n",
      "Epoch: 06 | Time: 74m 22s\n",
      "\tTrain Loss: 4.993 | Train PPL: 147.330\n",
      "\t Val. Loss: 5.701 |  Val. PPL: 299.087\n",
      "Epoch: 07 | Time: 74m 41s\n",
      "\tTrain Loss: 4.848 | Train PPL: 127.431\n",
      "\t Val. Loss: 5.636 |  Val. PPL: 280.362\n",
      "Epoch: 08 | Time: 78m 19s\n",
      "\tTrain Loss: 4.704 | Train PPL: 110.419\n",
      "\t Val. Loss: 5.628 |  Val. PPL: 278.098\n",
      "Epoch: 09 | Time: 80m 56s\n",
      "\tTrain Loss: 4.585 | Train PPL:  98.006\n",
      "\t Val. Loss: 5.606 |  Val. PPL: 272.053\n",
      "Epoch: 10 | Time: 77m 4s\n",
      "\tTrain Loss: 4.494 | Train PPL:  89.452\n",
      "\t Val. Loss: 5.605 |  Val. PPL: 271.658\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "best_valid_loss = float('inf')\n",
    "e11 = []\n",
    "e21 = []\n",
    "\n",
    "for epoch in range(num_epoch):    \n",
    "    start_time = time.time()\n",
    "    train_loss = train1(seq2seq, trainloader, optimizer, criterion)\n",
    "    e11.append(train_loss)\n",
    "    valid_loss = evaluate1(seq2seq, devloader, criterion)\n",
    "    e21.append(valid_loss)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(seq2seq.state_dict(), 'tut1-model2.pt')\n",
    "\n",
    "    # it's easier to see a change in perplexity between epoch as it's an exponential\n",
    "    # of the loss, hence the scale of the measure is much bigger\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 81m 6s\n",
      "\tTrain Loss: 4.398 | Train PPL:  81.280\n",
      "\t Val. Loss: 5.612 |  Val. PPL: 273.708\n",
      "Epoch: 12 | Time: 83m 3s\n",
      "\tTrain Loss: 4.312 | Train PPL:  74.614\n",
      "\t Val. Loss: 5.602 |  Val. PPL: 271.084\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10,12):    \n",
    "    start_time = time.time()\n",
    "    train_loss = train1(seq2seq, trainloader, optimizer, criterion)\n",
    "    e11.append(train_loss)\n",
    "    valid_loss = evaluate1(seq2seq, devloader, criterion)\n",
    "    e21.append(valid_loss)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(seq2seq.state_dict(), 'tut1-model2.pt')\n",
    "\n",
    "    # it's easier to see a change in perplexity between epoch as it's an exponential\n",
    "    # of the loss, hence the scale of the measure is much bigger\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load('tut1-model2.pt'))#Call the model with the best loss of validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqDghhU7F5Ut"
   },
   "source": [
    "###Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v767Mo6YGdLI"
   },
   "source": [
    "Note:\n",
    "1.   Embedding name for the training vocabulary: pre_train_weight.\n",
    "2.   seq2seq(text_batch, text_len, hl_batch, teacher_forcing_ratio=0)\\\n",
    "text_batch = [max_length_text(each batch), batch_size]\\\n",
    "text_len = real length of each text in the batch (a list)\\\n",
    "hl_batch = [max_length_hl(each batch), batch_size]\n",
    "3.   Outputs is a list with outputs of S2S as the element.\n",
    "     [max_length_hl(each batch), batch_size, vocabulary_size]\n",
    "4.   Predict is a list with prediction of each batch.\n",
    "     [max_length_hl, batch_size]\n",
    "5.   e1 and e2 are the collection of the training loss and validation loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f916c1a48e0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = range(1,13)\n",
    "plt.plot(n,e11)\n",
    "plt.plot(n,e21)\n",
    "plt.legend(['train loss','validation loss'])\n",
    "#plt.savefig('Seq-to-Seq256.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "e11 = np.array(e11)\n",
    "np.save('train loss 256.npy', e11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "e21 = np.array(e21)\n",
    "np.save('val loss 256.npy', e21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "target = []\n",
    "for text_batch, hl_batch, text_len, headline_len in testloader:\n",
    "    text_batch = torch.transpose(text_batch, 0, 1) \n",
    "    hl_batch = torch.transpose(hl_batch, 0, 1)\n",
    "    text_batch = text_batch[:text_len.max()]\n",
    "    hl_batch = hl_batch[:headline_len.max()]\n",
    "    with torch.no_grad():\n",
    "        a = seq2seq(text_batch, text_len, hl_batch, teacher_forcing_ratio=0)\n",
    "        a = a.argmax(2)\n",
    "    for i in range(a.shape[1]):\n",
    "        outputs.append(' '.join([headline_vocabulary.index2word[j] for j in a[:,i].numpy() if (j != 0) & (j != 1) & (j != 2)]))\n",
    "        target.append(' '.join([headline_vocabulary.index2word[j] for j in hl_batch[:,i].numpy() if (j != 0) & (j != 1) & (j != 2)])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "r1 = [rouge.get_scores(o, t)[0][\"rouge-1\"]['r'] for o, t in zip(outputs, target)]\n",
    "r2 = [rouge.get_scores(o, t)[0][\"rouge-2\"]['r'] for o, t in zip(outputs, target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge1 = np.array(r1).mean()\n",
    "rouge2 = np.array(r2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13478372918700593, 0.030525662924277365)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge1,rouge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yzfNmKuRieQ5"
   ],
   "name": "Untitled5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
